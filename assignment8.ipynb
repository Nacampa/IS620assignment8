{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load assignment8rev4.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# IS620 - Assignment 8\n",
      "# Program: assignment8rev4.py\n",
      "# Student: Neil Acampa\n",
      "# Date:    10/18/16\n",
      "# Function:\n",
      "\n",
      "\n",
      "\n",
      "# 1. Choose a corpus of interest.\n",
      "# 2. How many total unique words are in the corpus? (Please feel free to define unique words in any interesting, defensible way).\n",
      "\n",
      "# 1    -  Perform runs on two corpuses\n",
      "#      -  Read in Alice in Wonderland by Lewis Carroll on Pass1 \n",
      "#      -  Read Far from the Maddening Crowd by Thomas Hardy on Pass2\n",
      "#      -  Parse, remove special chars, set to lower case\n",
      "#      -  Update masterdict with unique words and count\n",
      "#      -  Update uniquewords: a 2 dimensional list of unique words and count\n",
      "#      -  vocab: Sort of words by descending word count\n",
      "#      -  vocab200: Top 200 words and word count\n",
      "#      -  Custom functions:  remove_characters, remove_symbols, find_word\n",
      "\n",
      "\n",
      "# 2    -  Use NLTK commands\n",
      "#      -  Read in gutenberg corpus book: Far from the Maddening Crowd by Thomas Hardy or Alice in Wonderland\n",
      "#      -  Strip punctuation\n",
      "#      -  Set words to lower case\n",
      "#      -  Tokenize ad sort\n",
      "\n",
      "# 3    -  Perform statistics\n",
      "#      -  wordcnt:   Count of Total words\n",
      "#      -  uniquecnt: Count of unique words\n",
      "#      -  wcnt:      Count of unique words that make up half of all words\n",
      "#      -  zipfs:     Array of zipf distribution for the Top 20 words\n",
      "#      -  teststat:  Test Chi Square stat (Observed - Expected)^2/Expected\n",
      "#                    teststat = (word cnt - zipf count)^2 / zipf count\n",
      "#         totChiStat: Test statictic \n",
      "#         ChiSquare : 9 dof and alpha .005: 38.582\n",
      "#      -  Test Zipfs distribution against our corpus\n",
      "\n",
      "#      -  Use FreqDist or Hist to show word frequency of top 200 words\n",
      "\n",
      "\n",
      "\n",
      "from __future__ import absolute_import \n",
      "from __future__ import division\n",
      "import re\n",
      "import os \n",
      "import math\n",
      "import decimal\n",
      "import numpy as np\n",
      "import scipy\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "from pandas import DataFrame\n",
      "import networkx as nx\n",
      "import random\n",
      "from urllib import urlopen\n",
      "import nltk\n",
      "nltk.download('gutenberg')\n",
      "from nltk import word_tokenize\n",
      "nltk.download('maxent_treebank_pos_tagger')\n",
      "nltk.download('punkt')\n",
      "tokenizer = nltk.data.load('nltk:tokenizers/punkt/english.pickle')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "linelst=[]\n",
      "lines  = \"\"\n",
      "allwords       = []   # Contains all words\n",
      "masterdict     = []   # Contains unique words\n",
      "masterdictcnt  = []   # Contains count of unique words corresponding to masterdict\n",
      "uniquewords    = []   # Contains unique words in the first dimension and the count in the second dim\n",
      "                      # Will try to use if it works for unique word count\n",
      "\n",
      "vocab          = []   # Unique words sorted by descending count\n",
      "vocab200       = []   # Top 200 vocabulary words\n",
      "\n",
      "vocabF         = []   # Vocabulary words for Freq Dist\n",
      "\n",
      "\n",
      "# Zipfs table Headings\n",
      "\n",
      "zheadings      = []\n",
      "zheadings.append(\"Term\")\n",
      "zheadings.append(\"Word\")\n",
      "zheadings.append(\"Obs\")\n",
      "zheadings.append(\"Exp\")\n",
      "zheadings.append(\"ChiSqStat\")\n",
      "\n",
      "\n",
      "zipfs          = []  # Zipfs frequencies\n",
      "chitest        = []  # Chi square test \n",
      "\n",
      "nltkflag       = 0   # Set to zero to use a local text file and functions\n",
      "                     # Set to 1 to use nltk commands\n",
      "halftot1       = []  # Store number of unique words reprenting 1/2 total words for pass 1\n",
      "halftot2       = []  # Store number of unique words reprenting 1/2 total words for pass 1\n",
      "\n",
      "rejectchars = [',','.','?','<','>','!','\"','-','%','&','#','(',')','*',';'];\n",
      "rcnt = len(rejectchars);\n",
      "\n",
      "\n",
      "def remove_characters(word):\n",
      "  \"\"\"Replace special characters in the word\"\"\"\n",
      "  \n",
      "  for i in range(rcnt):\n",
      "    rchar = rejectchars[i]\n",
      "    if rchar in word:\n",
      "      word = word.replace(rchar,\"\")\n",
      "\n",
      "  return word\n",
      "\n",
      "\n",
      "def remove_symbols(word):\n",
      "  \"\"\"Replace symbols in the word\"\"\"\n",
      "  w = len(word)\n",
      "  word = (ord(c) for c in word) \n",
      "  word = map(lambda x:x if x<123 or x>255 else \" \", word)\n",
      "  newword=\"\"\n",
      "  for c in range(w):\n",
      "    if word[c] <> \" \":\n",
      "      newword += chr(word[c]);\n",
      "  \n",
      "  return newword\n",
      "\n",
      "\n",
      "def find_word(word, masterdict):\n",
      "  \"\"\"Find and return index of word in dictionary\"\"\"\n",
      "\n",
      "  masterlen = len(masterdict)\n",
      "  find=0\n",
      "  temp=\"x\"\n",
      "  try:\n",
      "   temp = masterdict.index(word);\n",
      "   return temp\n",
      "  except ValueError:\n",
      "   return temp\n",
      "\n",
      "\n",
      "def display_hist(uniquevocab, corpus):\n",
      "  \"\"\"Display histogram of Top 200 most frequent words\"\"\"\n",
      "\n",
      "  title = (\"Histogram of Top 200 most frequent words in Corpus %s\") % (corpus)\n",
      "  plt.title(title) \n",
      "  plt.xlabel(\"Words\")\n",
      "  plt.ylabel(\"Count\")\n",
      "  yvalues = uniquevocab[1:]\n",
      "  xvalues = uniquevocab[0:]\n",
      "  plt.hist(yvalues, bins = 10, normed = True, color = 'b')\n",
      "  plt.grid(True)\n",
      "  fname = \"Word Frequency.png\"\n",
      "  plt.savefig(fname) # save as png\n",
      "  plt.show()\n",
      "  return\n",
      "\n",
      "\n",
      "\n",
      "def parse_data(linelst):\n",
      " \"\"\"Parse each line and update arrays\"\"\"\n",
      "\n",
      " return\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      " linecnt  = 0\n",
      " print\n",
      " filepath=\"\"\n",
      " temp    =\"\"\n",
      " tokens  = \"\"\n",
      " valid   = 0\n",
      " p       = 1\n",
      " cwd = os.getcwd()\n",
      " while (p <=2):\n",
      "  if (p == 1):\n",
      "   corpus     = \"Alice in Wonderland\"\n",
      "   fullcorpus = \"Alice in Wonderland by Lewis Carroll\"\n",
      "   currfilepath = str(cwd) + \"\\carroll-alice.txt\"\n",
      "  else: \n",
      "   corpus     = \"Far from the Maddening Crowd\"\n",
      "   fullcorpus = \"Far from the Maddening Crowd by Thomas Hardy\"\n",
      "   currfilepath = str(cwd) + \"\\crowd13.txt\"\n",
      "\n",
      "  print currfilepath\n",
      "  print (\"Enter the Full File Path including the File\")\n",
      "  print (\"or Press return to use current File Path %s\") % (currfilepath)\n",
      "  filepath = raw_input(\"Please enter the File Path now \")\n",
      "  valid = 0\n",
      "  if filepath == \"\":\n",
      "     filepath = currfilepath\n",
      "\n",
      " \n",
      "  try:\n",
      "       #f = open(\"c:\\carroll-alice.txt\",\"r\")\n",
      "       f = open(filepath,\"r\")\n",
      "       try:\n",
      "         valid=1\n",
      "         x =0\n",
      "         j=0\n",
      "         for lines in f:\n",
      "           lines = lines.rstrip()\n",
      "           temp = lines.split(\" \");\n",
      "           l = len(temp)\n",
      "           for x in range(l):\n",
      "             word = remove_characters(temp[x])\n",
      "             word = remove_symbols(word)\n",
      "             word = word.lower()\n",
      "             word = word.replace(\" \",\"\")\n",
      "             if (word != ''):\n",
      "               allwords.append(word)\n",
      "                     \n",
      "       finally:\n",
      "         if (nltkflag == 0):\n",
      "            f.close()\n",
      "         \n",
      "  except IOError:\n",
      "       print (\"File not Found - Program aborting\")\n",
      "\n",
      "  if not(valid):\n",
      "     exit()\n",
      " \n",
      " \n",
      "  wordcnt     = len(allwords)\n",
      "  halfwordcnt = int(wordcnt / 2)\n",
      "    \n",
      "  print \n",
      "  for x in range(wordcnt):\n",
      "    word = allwords[x]\n",
      "    findx = find_word(word, masterdict)\n",
      "    if (findx == \"x\"):\n",
      "       masterdict.append(word)\n",
      "       masterdictcnt.append(1)\n",
      "    else:\n",
      "       masterdictcnt[findx]+=1\n",
      "     \n",
      "      \n",
      "   \n",
      "\n",
      "  uniquecnt = len(masterdict)\n",
      "  print (\"Statistics for Corpus:  %s\") % (fullcorpus)\n",
      "  print\n",
      "  print(\"There are %d total words in the Corpus\") % (wordcnt)\n",
      "  print(\"There are %d total Unique words in the Corpus\") % (uniquecnt)\n",
      "  print\n",
      "\n",
      " \n",
      " \n",
      " \n",
      "  for i in range(uniquecnt):\n",
      "    uniquewords.append([masterdict[i], masterdictcnt[i]])\n",
      " \n",
      " \n",
      "  print (\"10 Unique Words in Corpus %s\") % (corpus)\n",
      "  for i in range(10):\n",
      "    print (uniquewords[i])\n",
      "\n",
      "\n",
      "  print\n",
      "  print \n",
      "  vocab = sorted(uniquewords, key = lambda w: w[1:], reverse = True)\n",
      "  print (\"Top 10 Unique Words in Corpus %s\") % (corpus)\n",
      "  for i in range(10):\n",
      "    print (vocab[i])\n",
      "\n",
      "\n",
      " \n",
      "# Now Find the number of unique words that represent halve of the entire corpus\n",
      "  i = -1\n",
      "  wcnt = 0\n",
      "  runtotal =0\n",
      "  while (runtotal <= halfwordcnt):\n",
      "    i=i+1\n",
      "    runtotal+=vocab[i][1]\n",
      "    wcnt=wcnt+1\n",
      "\n",
      "\n",
      "  print\n",
      "  print\n",
      "  print(\"%d unique words represent 1/2 of the Total number of Words: %d in %s\") % (wcnt, halfwordcnt, corpus)\n",
      "  if (p == 1):\n",
      "    halftot1.append(wcnt) \n",
      "    halftot1.append(halfwordcnt)\n",
      "    halftot1.append(corpus)\n",
      "  else:\n",
      "    halftot2.append(wcnt) \n",
      "    halftot2.append(halfwordcnt)\n",
      "    halftot2.append(corpus)\n",
      "\n",
      "  print\n",
      "  print(\"Frequency Distribution of Top 50 words\")\n",
      "  fd = nltk.FreqDist(allwords)\n",
      "  fd.plot(50,cumulative=False)\n",
      "\n",
      "  print\n",
      "  print(\"Frequency Distribution of Top 200 words\")\n",
      "  fd = nltk.FreqDist(allwords)\n",
      "  fd.plot(200,cumulative=False)\n",
      "\n",
      "  vocab200 = vocab[1:200]\n",
      "  #display_hist(vocab200, corpus)\n",
      "\n",
      "\n",
      "# Zipf's Law\n",
      "  print\n",
      "  print\n",
      "  print(\"Zipf's Law: T1 is the most common term in a collection,\")\n",
      "  print(\"            T2 is the next most common term in the collection\")\n",
      "  print(\"            The collection frequency of word cf(i) is proportional to 1/i * cf1\")\n",
      "  print\n",
      "  print(\"            The most common term occurs cf1 times\")\n",
      "  print(\"            The second most common term occurs 1/2 cf1 times\")\n",
      "  print(\"            The third  most common term occurs 1/3 cf1 times\")\n",
      "  print\n",
      "\n",
      " # Update zipfs frequencies \n",
      "  for i in range(20):\n",
      "   if (i == 0):\n",
      "     zipfs.append(vocab[i][1])\n",
      "   else:\n",
      "     temp = int(zipfs[0] / (i+1))\n",
      "     zipfs.append(temp)\n",
      "\n",
      " \n",
      "  print (\"Top 20 most Frequent words\")\n",
      "  print(\"Observed vrs Expected Word Frequencies\")\n",
      "  print (\"Expected Frequencies are based on Zipfs Law\")\n",
      "  print\n",
      "  print (\"Chi Square test statistic calculated: (O-E)^2/E for each term\")\n",
      "  print\n",
      "  print (\"%s\\t%s\\t%s\\t%s\\t%s\") % (zheadings[0], zheadings[1], zheadings[2], zheadings[3], zheadings[4])\n",
      "  indx=0\n",
      "  totChiStat=0\n",
      "  for i in range(20):\n",
      "   indx+=1\n",
      "   teststat = 0\n",
      "   teststat = (vocab[i][1] - zipfs[i])\n",
      "   teststat = math.pow(teststat,2)\n",
      "   teststat = teststat / zipfs[i]\n",
      "   print(\"%d\\t%s\\t%d\\t%d\\t%.2f\") % (indx, vocab[i][0], vocab[i][1], zipfs[i], teststat)\n",
      "   totChiStat+=teststat\n",
      "\n",
      "\n",
      "  print \n",
      "  print(\"h0: The observed relative frequency of words in %s follows Zipf's Law\") % (corpus)\n",
      "  print\n",
      "  print(\"h1: The observed relative frequency of words in %s does not follow Zipf's Law\") % (corpus)\n",
      "  print\n",
      "  print(\"The Test Statistic for 20 words is %.2f\") % (totChiStat)\n",
      "  print(\"At 19 dof the Chi Square for alpha .005 is 38.582\")\n",
      "  print(\"The probabiity of seeing a value of %.2f is less than .005\") % (totChiStat)\n",
      "  print\n",
      "  print(\"Reject h0 and conclude:\")\n",
      "  print(\"The observed relative frequency of words in this corpus does not follow Zipf's Law\")\n",
      "  print\n",
      "  print\n",
      "  print(\"If Zipf's law represents the expected frequency of the Distribution of words\")\n",
      "  print(\"Then by both visual inspection of the top 20 terms and by the ChiSquare test\")\n",
      "  print(\"this particular corpus: %s\") % (corpus)\n",
      "  print(\"does not follow Zipf's Law of word Distribution\")\n",
      "  print\n",
      "  print\n",
      "  p=p+1\n",
      " \n",
      " print\n",
      " print(\"Unique words representing 1/2 of the Total number of Words\")\n",
      " print\n",
      " pct1 = halftot1[0]/ halftot1[1]\n",
      " pct2 = halftot2[0]/ halftot2[1]\n",
      " print (\"%s\\t%s\\t%s\\t%s\\t%s\") % (\"Run\",\"Unique\",\"HalfTot\",\"Percent\", \"Corpus\")\n",
      " indx = 1\n",
      " print(\"%d\\t%d\\t%d\\t%.5f\\t%s\") % (indx, halftot1[0], halftot1[1], pct1, halftot1[2])\n",
      " indx = 2\n",
      " print(\"%d\\t%d\\t%d\\t%.5f\\t%s\") % (indx, halftot2[0], halftot2[1], pct2, halftot2[2])\n",
      " print\n",
      " print\n",
      " print(\"The percentage of Unique Words that account for 1/2 of the total words\")\n",
      " print(\"differs dramatically\")\n",
      " print\n",
      " print(\"This may be related to each Author's style, the topic, the time period\")\n",
      " print(\"More test would have to be performed in order to draw conclusions\")\n",
      " print\n",
      " print(\"Do all books written by a single Author show the same pattern?\")\n",
      " print\n",
      " print(\"Does a single Author's (unique word percentage of 1/2 total words) differ from book to book\")\n",
      " print\n",
      " print(\"Are the unique words themselves similar from book to book, are there paterns?\")\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      " \n",
      " \n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run assignment8rev4.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package gutenberg to\n",
        "[nltk_data]     C:\\Users\\nacampa\\AppData\\Roaming\\nltk_data...\n",
        "[nltk_data]   Package gutenberg is already up-to-date!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
        "[nltk_data]     C:\\Users\\nacampa\\AppData\\Roaming\\nltk_data...\n",
        "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
        "[nltk_data]       date!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[nltk_data] Downloading package punkt to\n",
        "[nltk_data]     C:\\Users\\nacampa\\AppData\\Roaming\\nltk_data...\n",
        "[nltk_data]   Package punkt is already up-to-date!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Anaconda2\\carroll-alice.txt\n",
        "Enter the Full File Path including the File\n",
        "or Press return to use current File Path C:\\Anaconda2\\carroll-alice.txt\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Please enter the File Path now \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Statistics for Corpus:  Alice in Wonderland by Lewis Carroll"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "There are 26383 total words in the Corpus\n",
        "There are 3509 total Unique words in the Corpus\n",
        "\n",
        "10 Unique Words in Corpus Alice in Wonderland\n",
        "[\"[alice's\", 1]\n",
        "['adventures', 5]\n",
        "['in', 353]\n",
        "['wonderland', 3]\n",
        "['by', 57]\n",
        "['lewis', 1]\n",
        "['carroll', 1]\n",
        "['1865]', 1]\n",
        "['chapter', 12]\n",
        "['i', 270]\n",
        "\n",
        "\n",
        "Top 10 Unique Words in Corpus Alice in Wonderland\n",
        "['the', 1607]\n",
        "['and', 787]\n",
        "['to', 710]\n",
        "['a', 615]\n",
        "['she', 532]\n",
        "['of', 493]\n",
        "['said', 455]\n",
        "['it', 439]\n",
        "['alice', 376]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['in', 353]\n",
        "\n",
        "\n",
        "72 unique words represent 1/2 of the Total number of Words: 13191 in Alice in Wonderland\n",
        "\n",
        "Frequency Distribution of Top 50 words\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Frequency Distribution of Top 200 words\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Zipf's Law: T1 is the most common term in a collection,\n",
        "            T2 is the next most common term in the collection\n",
        "            The collection frequency of word cf(i) is proportional to 1/i * cf1\n",
        "\n",
        "            The most common term occurs cf1 times\n",
        "            The second most common term occurs 1/2 cf1 times\n",
        "            The third  most common term occurs 1/3 cf1 times\n",
        "\n",
        "Top 20 most Frequent words\n",
        "Observed vrs Expected Word Frequencies\n",
        "Expected Frequencies are based on Zipfs Law\n",
        "\n",
        "Chi Square test statistic calculated: (O-E)^2/E for each term\n",
        "\n",
        "Term\tWord\tObs\tExp\tChiSqStat\n",
        "1\tthe\t1607\t1607\t0.00\n",
        "2\tand\t787\t803\t0.32\n",
        "3\tto\t710\t535\t57.24\n",
        "4\ta\t615\t401\t114.20\n",
        "5\tshe\t532\t321\t138.69\n",
        "6\tof\t493\t267\t191.30\n",
        "7\tsaid\t455\t229\t223.04\n",
        "8\tit\t439\t200\t285.61\n",
        "9\talice\t376\t178\t220.25\n",
        "10\tin\t353\t160\t232.81\n",
        "11\twas\t349\t146\t282.25\n",
        "12\tyou\t298\t133\t204.70\n",
        "13\ti\t270\t123\t175.68\n",
        "14\tas\t254\t114\t171.93\n",
        "15\ther\t242\t107\t170.33\n",
        "16\tthat\t231\t100\t171.61\n",
        "17\tat\t206\t94\t133.45\n",
        "18\ton\t180\t89\t93.04\n",
        "19\thad\t177\t84\t102.96\n",
        "20\twith\t175\t80\t112.81\n",
        "\n",
        "h0: The observed relative frequency of words in Alice in Wonderland follows Zipf's Law\n",
        "\n",
        "h1: The observed relative frequency of words in Alice in Wonderland does not follow Zipf's Law\n",
        "\n",
        "The Test Statistic for 20 words is 3082.23\n",
        "At 19 dof the Chi Square for alpha .005 is 38.582\n",
        "The probabiity of seeing a value of 3082.23 is less than .005\n",
        "\n",
        "Reject h0 and conclude:\n",
        "The observed relative frequency of words in this corpus does not follow Zipf's Law\n",
        "\n",
        "\n",
        "If Zipf's law represents the expected frequency of the Distribution of words\n",
        "Then by both visual inspection of the top 20 terms and by the ChiSquare test\n",
        "this particular corpus: Alice in Wonderland\n",
        "does not follow Zipf's Law of word Distribution\n",
        "\n",
        "\n",
        "C:\\Anaconda2\\crowd13.txt\n",
        "Enter the Full File Path including the File\n",
        "or Press return to use current File Path C:\\Anaconda2\\crowd13.txt\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Please enter the File Path now \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Statistics for Corpus:  Far from the Maddening Crowd by Thomas Hardy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "There are 165455 total words in the Corpus\n",
        "There are 14364 total Unique words in the Corpus\n",
        "\n",
        "10 Unique Words in Corpus Far from the Maddening Crowd"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[\"[alice's\", 1]\n",
        "['adventures', 5]\n",
        "['in', 353]\n",
        "['wonderland', 3]\n",
        "['by', 57]\n",
        "['lewis', 1]\n",
        "['carroll', 1]\n",
        "['1865]', 1]\n",
        "['chapter', 12]\n",
        "['i', 270]\n",
        "\n",
        "\n",
        "Top 10 Unique Words in Corpus Far from the Maddening Crowd"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['the', 11047]\n",
        "['and', 5881]\n",
        "['a', 5095]\n",
        "['to', 5013]\n",
        "['of', 4826]\n",
        "['in', 3086]\n",
        "['was', 2670]\n",
        "['i', 2564]\n",
        "['it', 2471]\n",
        "['she', 2322]\n",
        "\n",
        "\n",
        "45 unique words represent 1/2 of the Total number of Words: 82727 in Far from the Maddening Crowd\n",
        "\n",
        "Frequency Distribution of Top 50 words\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Frequency Distribution of Top 200 words\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Zipf's Law: T1 is the most common term in a collection,\n",
        "            T2 is the next most common term in the collection\n",
        "            The collection frequency of word cf(i) is proportional to 1/i * cf1\n",
        "\n",
        "            The most common term occurs cf1 times\n",
        "            The second most common term occurs 1/2 cf1 times\n",
        "            The third  most common term occurs 1/3 cf1 times\n",
        "\n",
        "Top 20 most Frequent words\n",
        "Observed vrs Expected Word Frequencies\n",
        "Expected Frequencies are based on Zipfs Law\n",
        "\n",
        "Chi Square test statistic calculated: (O-E)^2/E for each term\n",
        "\n",
        "Term\tWord\tObs\tExp\tChiSqStat\n",
        "1\tthe\t11047\t1607\t55453.39\n",
        "2\tand\t5881\t803\t32112.18\n",
        "3\ta\t5095\t535\t38866.54\n",
        "4\tto\t5013\t401\t53043.75\n",
        "5\tof\t4826\t321\t63224.38\n",
        "6\tin\t3086\t267\t29763.15\n",
        "7\twas\t2670\t229\t26019.57\n",
        "8\ti\t2564\t200\t27942.48\n",
        "9\tit\t2471\t178\t29538.48\n",
        "10\tshe\t2322\t160\t29214.03\n",
        "11\tyou\t2115\t146\t26554.53\n",
        "12\tthat\t2013\t133\t26574.44\n",
        "13\ther\t1961\t123\t27465.40\n",
        "14\tsaid\t1894\t114\t27792.98\n",
        "15\tas\t1707\t107\t23925.23\n",
        "16\the\t1615\t100\t22952.25\n",
        "17\tthe\t1607\t94\t24352.86\n",
        "18\thad\t1512\t89\t22752.01\n",
        "19\tat\t1363\t84\t19474.30\n",
        "20\twith\t1341\t80\t19876.51\n",
        "\n",
        "h0: The observed relative frequency of words in Far from the Maddening Crowd follows Zipf's Law\n",
        "\n",
        "h1: The observed relative frequency of words in Far from the Maddening Crowd does not follow Zipf's Law\n",
        "\n",
        "The Test Statistic for 20 words is 626898.46\n",
        "At 19 dof the Chi Square for alpha .005 is 38.582\n",
        "The probabiity of seeing a value of 626898.46 is less than .005\n",
        "\n",
        "Reject h0 and conclude:\n",
        "The observed relative frequency of words in this corpus does not follow Zipf's Law\n",
        "\n",
        "\n",
        "If Zipf's law represents the expected frequency of the Distribution of words\n",
        "Then by both visual inspection of the top 20 terms and by the ChiSquare test\n",
        "this particular corpus: Far from the Maddening Crowd\n",
        "does not follow Zipf's Law of word Distribution\n",
        "\n",
        "\n",
        "\n",
        "Unique words representing 1/2 of the Total number of Words\n",
        "\n",
        "Run\tUnique\tHalfTot\tPercent\tCorpus\n",
        "1\t72\t13191\t0.00546\tAlice in Wonderland\n",
        "2\t45\t82727\t0.00054\tFar from the Maddening Crowd\n",
        "\n",
        "\n",
        "The percentage of Unique Words that account for 1/2 of the total words\n",
        "differs dramatically\n",
        "\n",
        "This may be related to each Author's style, the topic, the time period\n",
        "More test would have to be performed in order to draw conclusions\n",
        "\n",
        "Do all books written by a single Author show the same pattern?\n",
        "\n",
        "Does a single Author's (unique word percentage of 1/2 total words) differ from book to book\n",
        "\n",
        "Are the unique words themselves similar from book to book, are there paterns?\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}